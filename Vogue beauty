import asyncio
import aiohttp
import feedparser
from collections import Counter
import re
from datetime import datetime, timezone

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
}

feeds = {
    "Beauty industry": "https://news.google.com/rss/search?q=beauty+industry&hl=en-GB&gl=GB&ceid=GB:en",
    "Cosmetics market": "https://news.google.com/rss/search?q=cosmetics+market&hl=en-GB&gl=GB&ceid=GB:en",
    "Skincare trends": "https://news.google.com/rss/search?q=skincare+trends&hl=en-GB&gl=GB&ceid=GB:en"
}

today = datetime.now(timezone.utc).date()
all_titles = []


async def fetch_feed(session, name, url):
    try:
        async with session.get(url, timeout=5) as response:
            text = await response.text()
            feed = feedparser.parse(text)
            print(f"Source: {name}")
            today_entries = []
            for entry in feed.entries:
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    entry_date = datetime(
                        *entry.published_parsed[:6], tzinfo=timezone.utc).date()
                    if entry_date == today:
                        today_entries.append(entry)
            print(f"Articles published today: {len(today_entries)}\n")
            for entry in today_entries[:5]:
                print("•", entry.title)
                all_titles.append(entry.title)
    except Exception as e:
        print(f"Could not fetch feed '{name}': {e}\n")


async def main():
    async with aiohttp.ClientSession(headers=HEADERS) as session:
        tasks = [fetch_feed(session, name, url) for name, url in feeds.items()]
        await asyncio.gather(*tasks)

# Run the async feed fetcher
asyncio.run(main())

# --- SUMMARY ---
print("\n=== TODAY'S TOP BEAUTY NEWS ===\n")
for title in all_titles[:10]:
    print("-", title)

# --- TREND ANALYSIS ---
words = []
for title in all_titles:
    cleaned = re.sub(r"[^a-zA-Z ]", "", title.lower())
    words.extend(cleaned.split())

stopwords = {
    "the", "and", "of", "in", "to", "for", "on", "with", "from", "this", "that",
    "will", "new", "about", "after", "over", "into"
}

keywords = [w for w in words if w not in stopwords and len(w) > 3]
trends = Counter(keywords).most_common(10)

print("\n=== TODAY'S EMERGING TREND KEYWORDS ===\n")
for word, count in trends:
    print(f"{word} ({count})")

# --- SAVE REPORT ---
with open("beauty_news_today.txt", "w") as f:
    f.write("TODAY'S BEAUTY NEWS\n")
    for title in all_titles[:10]:
        f.write(f"- {title}\n")

    f.write("\nEMERGING TRENDS\n")
    for word, count in trends:
        f.write(f"{word}: {count}\n")

    f.write("\n---\nThis page is hosted using GitHub Pages!\n")

print("\n✔ Today's report saved to beauty_news_today.txt\n")
