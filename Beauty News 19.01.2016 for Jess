import asyncio
import aiohttp
import feedparser
from collections import Counter
import re
from datetime import datetime, timezone

# HEADERS pentru cereri web
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
}

# RSS feeds
feeds = {
    "Beauty industry": "https://news.google.com/rss/search?q=beauty+industry&hl=en-GB&gl=GB&ceid=GB:en",
    "Cosmetics market": "https://news.google.com/rss/search?q=cosmetics+market&hl=en-GB&gl=GB&ceid=GB:en",
    "Skincare trends": "https://news.google.com/rss/search?q=skincare+trends&hl=en-GB&gl=GB&ceid=GB:en"
}

# Data de azi
today = datetime.now(timezone.utc).date()
today_str = today.isoformat()
filename = f"beauty_news_{today_str}.txt"

all_titles = []


async def fetch_feed(session, name, url):
    try:
        async with session.get(url, timeout=5) as response:
            text = await response.text()
            feed = feedparser.parse(text)
            print(f"\nSource: {name}")
            today_entries = []
            for entry in feed.entries:
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    entry_date = datetime(
                        *entry.published_parsed[:6], tzinfo=timezone.utc).date()
                    if entry_date == today:
                        today_entries.append(entry)
            print(f"Articles published today: {len(today_entries)}\n")
            for entry in today_entries[:10]:
                print("•", entry.title)
                all_titles.append(entry.title)
    except Exception as e:
        print(f"Could not fetch feed '{name}': {e}")


async def main():
    async with aiohttp.ClientSession(headers=HEADERS) as session:
        tasks = [fetch_feed(session, name, url) for name, url in feeds.items()]
        await asyncio.gather(*tasks)

# Rulează fetch
asyncio.run(main())

# --- Summary ---
print("\n=== TODAY'S TOP BEAUTY NEWS ===\n")
for title in all_titles[:10]:
    print("-", title)

# --- Trend Analysis ---
words = []
for title in all_titles:
    cleaned = re.sub(r"[^a-zA-Z ]", "", title.lower())
    words.extend(cleaned.split())

stopwords = {"the", "and", "of", "in", "to", "for", "on", "with", "from",
             "this", "that", "will", "new", "about", "after", "over", "into"}

keywords = [w for w in words if w not in stopwords and len(w) > 3]
trends = Counter(keywords).most_common(10)

print("\n=== TODAY'S EMERGING TREND KEYWORDS ===\n")
for word, count in trends:
    print(f"{word} ({count})")

# --- Save report ---
with open(filename, "w") as f:
    f.write(f"TODAY'S BEAUTY NEWS ({today_str})\n\n")
    for title in all_titles[:10]:
        f.write(f"- {title}\n")
    f.write("\nEMERGING TRENDS\n")
    for word, count in trends:
        f.write(f"{word}: {count}\n")
    f.write("\n---\nThis page is hosted using GitHub Pages!\n")

print(f"\n✔ Today's report saved to {filename}\n")
